{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc5e986-cea3-4f71-b5ec-3cd629691473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings # depricated\n",
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# from langchain.vectorstores import Chroma # depricated\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3994a53f-4229-4d2e-981e-796240833bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "# os.environ[\"OPENAI_API_BASE\"] = \"https://openai.vocareum.com/v1\"\n",
    "os.environ[\"WOKSPACE_JSON\"] = '../static/workspace_directories.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be77f134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15626092 -0.15891534 (384,)\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
    "st_embeddings = embedding_model.encode(\"Testing long text\")\n",
    "\n",
    "print(max(st_embeddings), min(st_embeddings), st_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4fec99f-f8c0-4bed-9487-6654200fc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Embeddings model and Chroma database\n",
    "# embedding_model = OpenAIEmbeddings() # Openai\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # Load SentenceTransformers model\n",
    "\n",
    "chroma_db_path = \"./chroma_db\"  # Path to store Chroma database\n",
    "vectorstore = Chroma(persist_directory=chroma_db_path, embedding_function=embedding_model)\n",
    "\n",
    "# Text splitter configuration\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Number of characters per chunk\n",
    "    chunk_overlap=100,  # Overlap between chunks to maintain context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0216c8e5-41a9-4043-a473-a70a84eaad97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\abdal\\\\Downloads\\\\Testing Pdf preview\\\\Automated_Mammography_Reporting_through_Image_to_Text_Translation - Copy (2).pdf',\n",
       " 'C:\\\\Users\\\\abdal\\\\Downloads\\\\Testing Pdf preview\\\\BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf',\n",
       " 'C:\\\\Users\\\\abdal\\\\Downloads\\\\Testing Pdf preview\\\\Towards Large-Scale Training of Pathology Foundation Models.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.environ[\"WOKSPACE_JSON\"]) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pdf_files_dirs = [os.path.join(data[0]['path'], f) for f in os.listdir(data[0]['path'])]\n",
    "pdf_files_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f73eec65-2641-4042-8d82-294587280539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automated_Mammography_Reporting_through_Image_to_Text_Translation - Copy (2).pdf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files_dirs[0].split('\\\\')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba0013fb-0ad5-4a30-b9db-cd8809b9ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in pdf_files_dirs:\n",
    "    \n",
    "    with open(file, 'rb') as f:\n",
    "        # read the pdf\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "\n",
    "        # concat all text\n",
    "        pdf_full_text = ''.join(page.extract_text() for page in reader.pages)\n",
    "\n",
    "        # split into chuncks\n",
    "        pdf_chunks = text_splitter.split_text(pdf_full_text)\n",
    "\n",
    "        # Create Document objects for each chunk\n",
    "        pdf_documents = [\n",
    "            Document(page_content=chunk, metadata={\"file_name\": file.split('\\\\')[-1], \"chunk_index\": idx})\n",
    "            for idx, chunk in enumerate(pdf_chunks)\n",
    "        ]\n",
    "        \n",
    "        # Add the documents to Chroma\n",
    "        vectorstore.add_documents(pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee09dfb-0fdf-4570-ade1-8995daa048c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document = Document(pdf_full_text, metadata={\"file_name\": pdf_doc_path.split('\\\\')[-1]})\n",
    "# document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c312a94-0378-4578-aceb-2daefcf8dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the text into chunks\n",
    "# chunks = text_splitter.split_text(pdf_full_text)\n",
    "\n",
    "# print(len(chunks))\n",
    "# print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd142e55-fac3-4ee5-bfe0-1a06aa40d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Document objects for each chunk\n",
    "# documents = [\n",
    "#     Document(page_content=chunk, metadata={\"file_name\": pdf_doc_path.split('\\\\')[-1], \"chunk_index\": idx})\n",
    "#     for idx, chunk in enumerate(chunks)\n",
    "# ]\n",
    "# documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fa88d98-be01-481b-ad55-59ce8ae90a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add the documents to Chroma\n",
    "# vectorstore.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff7d511b-fb1c-4025-9ca0-40187f394fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33495311-873b-4967-b713-fad79a8af1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform similarity search\n",
    "# query = \"mammography report generation is performed using a series of zero-shot classification tasks\"\n",
    "# results = vectorstore.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cc6c8dd-04b1-48c3-b4b4-6a0f3af713dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.034560106694698334,\n",
       " 0.052149612456560135,\n",
       " -0.007049025967717171,\n",
       " 0.03573371097445488,\n",
       " -0.0349850095808506,\n",
       " 0.01494691800326109,\n",
       " -0.04320145025849342,\n",
       " 0.03119904361665249,\n",
       " -0.0539119653403759,\n",
       " -0.010592584498226643,\n",
       " 0.03282345458865166,\n",
       " -0.0709524005651474,\n",
       " 0.017137382179498672,\n",
       " -0.01121582742780447,\n",
       " -0.06640471518039703,\n",
       " 0.018585706129670143,\n",
       " -0.07146716862916946,\n",
       " 0.03463846817612648,\n",
       " 0.05622696503996849,\n",
       " -0.0010497522307559848,\n",
       " 0.0738152265548706,\n",
       " 0.032592665404081345,\n",
       " -0.016740525141358376,\n",
       " -0.04814876243472099,\n",
       " 0.08016165345907211,\n",
       " -0.026738863438367844,\n",
       " -0.03598518297076225,\n",
       " 0.000247649266384542,\n",
       " 0.03442370891571045,\n",
       " 0.011950265616178513,\n",
       " 0.023524945601820946,\n",
       " 0.03089885227382183,\n",
       " 0.11152336001396179,\n",
       " 0.04445668309926987,\n",
       " 0.004069797694683075,\n",
       " -0.02472517639398575,\n",
       " 0.012798914685845375,\n",
       " 0.08923646062612534,\n",
       " -0.04597149416804314,\n",
       " -0.018967395648360252,\n",
       " 0.006144956685602665,\n",
       " -0.020748233422636986,\n",
       " 0.06660695374011993,\n",
       " -0.035692278295755386,\n",
       " 0.03694979101419449,\n",
       " 0.0010053495643660426,\n",
       " -0.08200832456350327,\n",
       " 0.07332616299390793,\n",
       " -0.02508372813463211,\n",
       " 0.1142745316028595,\n",
       " -0.1023203507065773,\n",
       " -0.08329086005687714,\n",
       " -0.09090038388967514,\n",
       " -0.018495924770832062,\n",
       " 0.055122651159763336,\n",
       " -0.01823391765356064,\n",
       " 0.049198299646377563,\n",
       " -0.0329904742538929,\n",
       " -0.016779368743300438,\n",
       " -0.050631459802389145,\n",
       " -0.05080239102244377,\n",
       " -0.008842376992106438,\n",
       " -0.06411314010620117,\n",
       " 0.052459027618169785,\n",
       " 0.09670837968587875,\n",
       " 0.03001715987920761,\n",
       " 0.0035714146215468645,\n",
       " 0.012516594491899014,\n",
       " -0.006369903218001127,\n",
       " -0.02164647728204727,\n",
       " -0.1218363344669342,\n",
       " -0.05863252282142639,\n",
       " -0.023871518671512604,\n",
       " 0.04793497547507286,\n",
       " -0.10381363332271576,\n",
       " 0.08406248688697815,\n",
       " -0.0019307482289150357,\n",
       " -0.014440607279539108,\n",
       " 0.06279321014881134,\n",
       " 0.056401368230581284,\n",
       " 0.06531314551830292,\n",
       " -0.019616631790995598,\n",
       " 0.11099415272474289,\n",
       " -0.054563023149967194,\n",
       " 0.011862853541970253,\n",
       " -0.017172759398818016,\n",
       " 0.04294692352414131,\n",
       " 0.018976908177137375,\n",
       " 0.008258926682174206,\n",
       " -0.05649278312921524,\n",
       " -0.025338107720017433,\n",
       " 0.0370994471013546,\n",
       " -0.07256248593330383,\n",
       " 0.06105276942253113,\n",
       " -0.009058045223355293,\n",
       " -0.011253716424107552,\n",
       " -0.10719481110572815,\n",
       " 0.007094904314726591,\n",
       " 0.06904284656047821,\n",
       " 0.03298862650990486,\n",
       " 0.04739729315042496,\n",
       " 0.007287151645869017,\n",
       " 0.0271739661693573,\n",
       " -0.01883062720298767,\n",
       " -0.00573317427188158,\n",
       " -0.0679190382361412,\n",
       " 0.05742455646395683,\n",
       " -0.06014140695333481,\n",
       " 0.00908678863197565,\n",
       " -0.004898037761449814,\n",
       " 0.054621823132038116,\n",
       " 0.0759972408413887,\n",
       " -0.046833623200654984,\n",
       " -0.10494816303253174,\n",
       " 0.09218477457761765,\n",
       " -0.0004104765539523214,\n",
       " -0.011146348901093006,\n",
       " 0.005757697392255068,\n",
       " 0.04767915606498718,\n",
       " -0.01729963906109333,\n",
       " -0.033763665705919266,\n",
       " -0.004466027021408081,\n",
       " -0.07832574099302292,\n",
       " -0.006834412459284067,\n",
       " 0.10111045837402344,\n",
       " 0.07964979857206345,\n",
       " 0.027600886300206184,\n",
       " -1.0627542488383566e-33,\n",
       " -0.01047589723020792,\n",
       " -0.019130930304527283,\n",
       " 0.0979941114783287,\n",
       " 0.002976845484226942,\n",
       " 0.05192355066537857,\n",
       " 0.0303372573107481,\n",
       " -0.0315069742500782,\n",
       " -0.1437745839357376,\n",
       " 0.005555053241550922,\n",
       " -0.045032650232315063,\n",
       " 0.0020552135538309813,\n",
       " 0.014699229970574379,\n",
       " -0.03249412775039673,\n",
       " -0.034309741109609604,\n",
       " 0.06332500278949738,\n",
       " -0.011554049327969551,\n",
       " 0.05615800991654396,\n",
       " 0.08327797055244446,\n",
       " -0.04600534215569496,\n",
       " 0.07464627921581268,\n",
       " -0.030901912599802017,\n",
       " -0.06390009075403214,\n",
       " 0.012175709009170532,\n",
       " 0.04669967666268349,\n",
       " 0.08695109188556671,\n",
       " 0.0995999127626419,\n",
       " 0.061920229345560074,\n",
       " 0.005985603667795658,\n",
       " -0.021744783967733383,\n",
       " -0.014164775609970093,\n",
       " -0.015186445787549019,\n",
       " -0.012922297231853008,\n",
       " 0.01786905527114868,\n",
       " -0.03329238295555115,\n",
       " -0.06864692270755768,\n",
       " 0.006788825616240501,\n",
       " 0.005305063910782337,\n",
       " -0.015176489017903805,\n",
       " 0.014475319534540176,\n",
       " 0.011958261951804161,\n",
       " 0.04016760736703873,\n",
       " 0.028898637741804123,\n",
       " 0.07369852066040039,\n",
       " -0.024323271587491035,\n",
       " -0.06185586377978325,\n",
       " -0.002172397915273905,\n",
       " -0.0921040028333664,\n",
       " 0.06269299983978271,\n",
       " 0.021808311343193054,\n",
       " 0.03625829890370369,\n",
       " 0.05621746927499771,\n",
       " -0.06217993423342705,\n",
       " -0.06861726194620132,\n",
       " -0.035807911306619644,\n",
       " 0.007846232503652573,\n",
       " 0.02917472831904888,\n",
       " -0.06298881024122238,\n",
       " -0.01802024058997631,\n",
       " -0.020451389253139496,\n",
       " 0.022566916421055794,\n",
       " 0.012717610225081444,\n",
       " -0.035808343440294266,\n",
       " 0.0655236765742302,\n",
       " 0.030720919370651245,\n",
       " 0.055353302508592606,\n",
       " -0.014346202835440636,\n",
       " -0.014439950697124004,\n",
       " 0.02250070497393608,\n",
       " 0.012945320457220078,\n",
       " 0.051578257232904434,\n",
       " -0.032981596887111664,\n",
       " 0.03099084086716175,\n",
       " -0.029620474204421043,\n",
       " -0.06036796048283577,\n",
       " -0.010843590833246708,\n",
       " 0.03681275621056557,\n",
       " 0.04072485864162445,\n",
       " 0.044797658920288086,\n",
       " -0.06156482547521591,\n",
       " 0.007144668605178595,\n",
       " -0.041010018438100815,\n",
       " 0.07141277939081192,\n",
       " -0.062451135367155075,\n",
       " -0.11558657884597778,\n",
       " 0.042687997221946716,\n",
       " -0.02237078733742237,\n",
       " 0.014761584810912609,\n",
       " 0.00746346078813076,\n",
       " 0.006835392210632563,\n",
       " -0.06848196685314178,\n",
       " 0.02459566853940487,\n",
       " 0.10797403752803802,\n",
       " -0.0480528324842453,\n",
       " 0.07394036650657654,\n",
       " 0.0010668978793546557,\n",
       " 6.149422372174174e-34,\n",
       " -0.008284248411655426,\n",
       " 0.08313805609941483,\n",
       " 0.06921026855707169,\n",
       " 0.0795927494764328,\n",
       " 0.000457264541182667,\n",
       " -0.021355289965867996,\n",
       " -0.020681295543909073,\n",
       " 0.05657530203461647,\n",
       " -0.06289707869291306,\n",
       " 0.0009534393320791423,\n",
       " -0.034191615879535675,\n",
       " -0.0702054500579834,\n",
       " -0.07052356749773026,\n",
       " -0.09413353353738785,\n",
       " -0.05078691989183426,\n",
       " -0.05334915220737457,\n",
       " 0.0684434100985527,\n",
       " -0.02693875879049301,\n",
       " 0.0014114679070189595,\n",
       " 0.012813089415431023,\n",
       " 0.044991739094257355,\n",
       " 0.0476168729364872,\n",
       " 0.02741381525993347,\n",
       " 0.016911916434764862,\n",
       " -0.10608793795108795,\n",
       " 0.02179075963795185,\n",
       " 0.009969347156584263,\n",
       " -0.09921597689390182,\n",
       " -0.00487768929451704,\n",
       " -0.029361840337514877,\n",
       " 0.0022298183757811785,\n",
       " 0.018052363768219948,\n",
       " 0.014170505106449127,\n",
       " 0.03234120458364487,\n",
       " 0.010857216082513332,\n",
       " -0.014337091706693172,\n",
       " 0.050246916711330414,\n",
       " 0.008571718819439411,\n",
       " 0.0907546654343605,\n",
       " 0.03996995463967323,\n",
       " -0.007000172045081854,\n",
       " 0.05102437362074852,\n",
       " -0.08133441209793091,\n",
       " -0.05332610383629799,\n",
       " -0.0583287850022316,\n",
       " -0.0031034837011247873,\n",
       " 0.1264616996049881,\n",
       " 0.041603948920965195,\n",
       " 0.027645649388432503,\n",
       " -0.03916342929005623,\n",
       " -0.09583403170108795,\n",
       " -0.026783974841237068,\n",
       " -0.027370501309633255,\n",
       " -0.011424917727708817,\n",
       " -0.13780929148197174,\n",
       " 0.02517256885766983,\n",
       " -0.03737197071313858,\n",
       " -0.023524517193436623,\n",
       " 0.007351727690547705,\n",
       " 0.051481541246175766,\n",
       " -0.016957998275756836,\n",
       " 0.029104050248861313,\n",
       " -0.10759308934211731,\n",
       " -0.13362663984298706,\n",
       " -0.0005386865814216435,\n",
       " 0.06331280618906021,\n",
       " 0.03559928387403488,\n",
       " -0.027042564004659653,\n",
       " -0.09014585614204407,\n",
       " 0.060980938374996185,\n",
       " -0.0026046023704111576,\n",
       " 0.05907565355300903,\n",
       " 0.024408411234617233,\n",
       " 0.013276124373078346,\n",
       " 0.08996303379535675,\n",
       " -0.004908425733447075,\n",
       " -0.03612180054187775,\n",
       " 0.022733541205525398,\n",
       " -0.02925821579992771,\n",
       " 0.00029938056832179427,\n",
       " 0.04533521831035614,\n",
       " 0.01251611951738596,\n",
       " 0.017444735392928123,\n",
       " 0.09466464072465897,\n",
       " -0.012266850098967552,\n",
       " -0.02213510312139988,\n",
       " 0.01622818596661091,\n",
       " -0.024578053504228592,\n",
       " -0.03346511721611023,\n",
       " -0.038512516766786575,\n",
       " -0.06601276248693466,\n",
       " 0.03671311214566231,\n",
       " 0.04891101270914078,\n",
       " 0.022375544533133507,\n",
       " -0.012167640961706638,\n",
       " -1.6788685996971253e-08,\n",
       " 0.007490688469260931,\n",
       " -0.03226161003112793,\n",
       " 0.041434936225414276,\n",
       " -0.06130420044064522,\n",
       " 0.02070990949869156,\n",
       " 0.02877584658563137,\n",
       " -0.05374447628855705,\n",
       " 0.003277129726484418,\n",
       " 0.059065744280815125,\n",
       " -0.029076479375362396,\n",
       " -0.02691545896232128,\n",
       " -0.0702529326081276,\n",
       " -0.1201247051358223,\n",
       " -0.0250258706510067,\n",
       " 0.03788548707962036,\n",
       " -0.04733342304825783,\n",
       " -0.014098349027335644,\n",
       " 0.06636448204517365,\n",
       " -0.044193416833877563,\n",
       " -0.06658182293176651,\n",
       " 0.006867139134556055,\n",
       " -0.029160629957914352,\n",
       " 0.02573605440557003,\n",
       " 0.047524936497211456,\n",
       " -0.014054530300199986,\n",
       " 0.03362221643328667,\n",
       " -0.041379962116479874,\n",
       " 0.0721946433186531,\n",
       " 0.03694145753979683,\n",
       " 0.058378398418426514,\n",
       " 0.052309613674879074,\n",
       " 0.05209032818675041,\n",
       " -0.02027161419391632,\n",
       " 0.023928988724946976,\n",
       " -0.058529410511255264,\n",
       " -0.03270725533366203,\n",
       " 0.008657301776111126,\n",
       " 0.004114746116101742,\n",
       " 0.04873114451766014,\n",
       " 0.04346231371164322,\n",
       " 0.004495072178542614,\n",
       " -0.06250167638063431,\n",
       " 0.05097843334078789,\n",
       " 0.00026355922454968095,\n",
       " -0.11217962205410004,\n",
       " 0.013766423799097538,\n",
       " 0.09116023033857346,\n",
       " -0.09570501744747162,\n",
       " -0.017665090039372444,\n",
       " -0.012416594661772251,\n",
       " 0.01208934560418129,\n",
       " -0.11012239754199982,\n",
       " 0.022578420117497444,\n",
       " 0.02684463933110237,\n",
       " -0.019359176978468895,\n",
       " 0.07996246963739395,\n",
       " 0.12798836827278137,\n",
       " 0.008362527005374432,\n",
       " 0.08307057619094849,\n",
       " 0.04925527051091194,\n",
       " -0.011634579859673977,\n",
       " -0.08714838325977325,\n",
       " -0.02170596271753311,\n",
       " 0.03383535146713257]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get query embedding\n",
    "query = \"mammography report generation approach using mmg-clip\"\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77f0b392-2ee1-4d7f-9eaa-2607a09175eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'chunk_index': 28, 'file_name': 'Automated_Mammography_Reporting_through_Image_to_Text_Translation - Copy (2).pdf'}, page_content='not collected or available), and a long Dutch report. It\\nconsists of 10,801 exam-report samples. Among all of\\nthose samples, only 1832 were applicable to be used,\\nexcluding several pathology, biopsy, or duplicates and\\nonly selecting mammogram reports. We also extracted\\nlabels from the sentences and manually translated them\\nto their English labels found in BI-RADS guidelines to\\nminimize the translation error.\\nMulti-label Prompts are sentences generated ran-\\ndomly that contain one or more labels information.\\nThese sentences are formed by randomly selecting a\\ntemplate sentence describing each label, and concate-\\nnating them to form one or more sentences describingMMG-CLIP: Automated Mammography Reporting through Image-to-Text Translation 7\\n(a) Model output on two malignancy evaluation prompts\\n (b) Model output on three mass shape evaluation prompts\\n(c) Model output on four mass margin evaluation prompts\\n (d) Model output on four mass density evaluation prompts'),\n",
       "  0.661310613155365),\n",
       " (Document(metadata={'chunk_index': 28, 'file_name': 'Automated_Mammography_Reporting_through_Image_to_Text_Translation - Copy (2).pdf'}, page_content='not collected or available), and a long Dutch report. It\\nconsists of 10,801 exam-report samples. Among all of\\nthose samples, only 1832 were applicable to be used,\\nexcluding several pathology, biopsy, or duplicates and\\nonly selecting mammogram reports. We also extracted\\nlabels from the sentences and manually translated them\\nto their English labels found in BI-RADS guidelines to\\nminimize the translation error.\\nMulti-label Prompts are sentences generated ran-\\ndomly that contain one or more labels information.\\nThese sentences are formed by randomly selecting a\\ntemplate sentence describing each label, and concate-\\nnating them to form one or more sentences describingMMG-CLIP: Automated Mammography Reporting through Image-to-Text Translation 7\\n(a) Model output on two malignancy evaluation prompts\\n (b) Model output on three mass shape evaluation prompts\\n(c) Model output on four mass margin evaluation prompts\\n (d) Model output on four mass density evaluation prompts'),\n",
       "  0.661310613155365),\n",
       " (Document(metadata={'chunk_index': 28, 'file_name': 'Automated_Mammography_Reporting_through_Image_to_Text_Translation - Copy (2).pdf'}, page_content='not collected or available), and a long Dutch report. It\\nconsists of 10,801 exam-report samples. Among all of\\nthose samples, only 1832 were applicable to be used,\\nexcluding several pathology, biopsy, or duplicates and\\nonly selecting mammogram reports. We also extracted\\nlabels from the sentences and manually translated them\\nto their English labels found in BI-RADS guidelines to\\nminimize the translation error.\\nMulti-label Prompts are sentences generated ran-\\ndomly that contain one or more labels information.\\nThese sentences are formed by randomly selecting a\\ntemplate sentence describing each label, and concate-\\nnating them to form one or more sentences describingMMG-CLIP: Automated Mammography Reporting through Image-to-Text Translation 7\\n(a) Model output on two malignancy evaluation prompts\\n (b) Model output on three mass shape evaluation prompts\\n(c) Model output on four mass margin evaluation prompts\\n (d) Model output on four mass density evaluation prompts'),\n",
       "  0.661310613155365),\n",
       " (Document(metadata={'chunk_index': 28, 'file_name': 'Automated_Mammography_Reporting_through_Image_to_Text_Translation - Copy (2).pdf'}, page_content='not collected or available), and a long Dutch report. It\\nconsists of 10,801 exam-report samples. Among all of\\nthose samples, only 1832 were applicable to be used,\\nexcluding several pathology, biopsy, or duplicates and\\nonly selecting mammogram reports. We also extracted\\nlabels from the sentences and manually translated them\\nto their English labels found in BI-RADS guidelines to\\nminimize the translation error.\\nMulti-label Prompts are sentences generated ran-\\ndomly that contain one or more labels information.\\nThese sentences are formed by randomly selecting a\\ntemplate sentence describing each label, and concate-\\nnating them to form one or more sentences describingMMG-CLIP: Automated Mammography Reporting through Image-to-Text Translation 7\\n(a) Model output on two malignancy evaluation prompts\\n (b) Model output on three mass shape evaluation prompts\\n(c) Model output on four mass margin evaluation prompts\\n (d) Model output on four mass density evaluation prompts'),\n",
       "  0.661310613155365),\n",
       " (Document(metadata={'chunk_index': 12, 'file_name': 'Automated_Mammography_Reporting_through_Image_to_Text_Translation - Copy (2).pdf'}, page_content='text reports, leaving a vast majority of image-label\\ndatasets unused to tackle the report generation task.2.4. Contributions of this work\\nThe main contribution of this work is summarized as\\nfollows:\\n1. To our knowledge, this is the first work to utilize\\nCLIP approach in mammography X-ray domain\\nfor mammography report generation. We tackle\\nthe lack of data by utilizing image-label and exam-\\nreports paired datasets, as well as generating text\\nprompts based on available labels to support the\\ntraining. Our method, namely MMG-CLIP , does\\nnot depend on a ruler-based labeler, and doesn’t re-\\nquire bounding boxes or small-patched images for\\ntraining, and can be adapted to any image-label or\\nexam-reports dataset.\\n2. We implemented a training approach that utilizes\\nfour views per exam, pairing them to the same\\ntext description, whether a label, a generated text\\nprompt, or a report used during training or evalua-\\ntion.\\n3. Performance of our model is validated on mul-'),\n",
       "  0.693875253200531)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform similarity search and retrieve scores\n",
    "query = \"mammography report generation approach using mmg-clip\"\n",
    "results_score = vectorstore.similarity_search_with_score(query, k=5)\n",
    "results_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d97c9516-7148-4b8c-be1d-9c3e832f0eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.661310613155365"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_score[0][1]#.metadata#.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34ea2e6f-f0ce-4e92-82c2-9d24b7ac1ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'sian error linear units. CoRR , abs/1606.08415.\\nFelix Hill, Kyunghyun Cho, and Anna Korhonen. 2016.\\nLearning distributed representations of sentences\\nfrom unlabelled data. In Proceedings of the 2016\\nConference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human\\nLanguage Technologies . Association for Computa-\\ntional Linguistics.\\nJeremy Howard and Sebastian Ruder. 2018. Universal\\nlanguage model ﬁne-tuning for text classiﬁcation. In\\nACL. Association for Computational Linguistics.\\nMinghao Hu, Yuxing Peng, Zhen Huang, Xipeng Qiu,\\nFuru Wei, and Ming Zhou. 2018. Reinforced\\nmnemonic reader for machine reading comprehen-\\nsion. In IJCAI .\\nYacine Jernite, Samuel R. Bowman, and David Son-\\ntag. 2017. Discourse-based objectives for fast un-\\nsupervised sentence representation learning. CoRR ,\\nabs/1705.00557.Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke\\nZettlemoyer. 2017. Triviaqa: A large scale distantly\\nsupervised challenge dataset for reading comprehen-',\n",
       "  'file_name': 'BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf',\n",
       "  'chunk_index': 46,\n",
       "  'similarity': 0.8222783803939819},\n",
       " {'text': 'sian error linear units. CoRR , abs/1606.08415.\\nFelix Hill, Kyunghyun Cho, and Anna Korhonen. 2016.\\nLearning distributed representations of sentences\\nfrom unlabelled data. In Proceedings of the 2016\\nConference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human\\nLanguage Technologies . Association for Computa-\\ntional Linguistics.\\nJeremy Howard and Sebastian Ruder. 2018. Universal\\nlanguage model ﬁne-tuning for text classiﬁcation. In\\nACL. Association for Computational Linguistics.\\nMinghao Hu, Yuxing Peng, Zhen Huang, Xipeng Qiu,\\nFuru Wei, and Ming Zhou. 2018. Reinforced\\nmnemonic reader for machine reading comprehen-\\nsion. In IJCAI .\\nYacine Jernite, Samuel R. Bowman, and David Son-\\ntag. 2017. Discourse-based objectives for fast un-\\nsupervised sentence representation learning. CoRR ,\\nabs/1705.00557.Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke\\nZettlemoyer. 2017. Triviaqa: A large scale distantly\\nsupervised challenge dataset for reading comprehen-',\n",
       "  'file_name': 'BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf',\n",
       "  'chunk_index': 46,\n",
       "  'similarity': 0.8222783803939819},\n",
       " {'text': 'sian error linear units. CoRR , abs/1606.08415.\\nFelix Hill, Kyunghyun Cho, and Anna Korhonen. 2016.\\nLearning distributed representations of sentences\\nfrom unlabelled data. In Proceedings of the 2016\\nConference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human\\nLanguage Technologies . Association for Computa-\\ntional Linguistics.\\nJeremy Howard and Sebastian Ruder. 2018. Universal\\nlanguage model ﬁne-tuning for text classiﬁcation. In\\nACL. Association for Computational Linguistics.\\nMinghao Hu, Yuxing Peng, Zhen Huang, Xipeng Qiu,\\nFuru Wei, and Ming Zhou. 2018. Reinforced\\nmnemonic reader for machine reading comprehen-\\nsion. In IJCAI .\\nYacine Jernite, Samuel R. Bowman, and David Son-\\ntag. 2017. Discourse-based objectives for fast un-\\nsupervised sentence representation learning. CoRR ,\\nabs/1705.00557.Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke\\nZettlemoyer. 2017. Triviaqa: A large scale distantly\\nsupervised challenge dataset for reading comprehen-',\n",
       "  'file_name': 'BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf',\n",
       "  'chunk_index': 46,\n",
       "  'similarity': 0.8222783803939819},\n",
       " {'text': 'textualized word vectors. In NIPS .\\nOren Melamud, Jacob Goldberger, and Ido Dagan.\\n2016. context2vec: Learning generic context em-\\nbedding with bidirectional LSTM. In CoNLL .\\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\\nrado, and Jeff Dean. 2013. Distributed representa-\\ntions of words and phrases and their compositional-\\nity. In Advances in Neural Information Processing\\nSystems 26 , pages 3111–3119. Curran Associates,\\nInc.\\nAndriy Mnih and Geoffrey E Hinton. 2009. A scal-\\nable hierarchical distributed language model. In\\nD. Koller, D. Schuurmans, Y . Bengio, and L. Bot-\\ntou, editors, Advances in Neural Information Pro-\\ncessing Systems 21 , pages 1081–1088. Curran As-\\nsociates, Inc.\\nAnkur P Parikh, Oscar T ¨ackstr ¨om, Dipanjan Das, and\\nJakob Uszkoreit. 2016. A decomposable attention\\nmodel for natural language inference. In EMNLP .\\nJeffrey Pennington, Richard Socher, and Christo-\\npher D. Manning. 2014. Glove: Global vectors for\\nword representation. In Empirical Methods in Nat-',\n",
       "  'file_name': 'BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf',\n",
       "  'chunk_index': 48,\n",
       "  'similarity': 0.8412410616874695},\n",
       " {'text': 'textualized word vectors. In NIPS .\\nOren Melamud, Jacob Goldberger, and Ido Dagan.\\n2016. context2vec: Learning generic context em-\\nbedding with bidirectional LSTM. In CoNLL .\\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\\nrado, and Jeff Dean. 2013. Distributed representa-\\ntions of words and phrases and their compositional-\\nity. In Advances in Neural Information Processing\\nSystems 26 , pages 3111–3119. Curran Associates,\\nInc.\\nAndriy Mnih and Geoffrey E Hinton. 2009. A scal-\\nable hierarchical distributed language model. In\\nD. Koller, D. Schuurmans, Y . Bengio, and L. Bot-\\ntou, editors, Advances in Neural Information Pro-\\ncessing Systems 21 , pages 1081–1088. Curran As-\\nsociates, Inc.\\nAnkur P Parikh, Oscar T ¨ackstr ¨om, Dipanjan Das, and\\nJakob Uszkoreit. 2016. A decomposable attention\\nmodel for natural language inference. In EMNLP .\\nJeffrey Pennington, Richard Socher, and Christo-\\npher D. Manning. 2014. Glove: Global vectors for\\nword representation. In Empirical Methods in Nat-',\n",
       "  'file_name': 'BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf',\n",
       "  'chunk_index': 48,\n",
       "  'similarity': 0.8412410616874695}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format the response\n",
    "response = [\n",
    "    {\n",
    "        \"text\": result[0].page_content,\n",
    "        \"file_name\": result[0].metadata.get(\"file_name\"),\n",
    "        \"chunk_index\": result[0].metadata.get(\"chunk_index\"),\n",
    "        \"similarity\": result[1]\n",
    "    } for result in results_score\n",
    "]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356adee-5f92-4574-a91f-4852eb41edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the db using DB Browser for SQLite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
